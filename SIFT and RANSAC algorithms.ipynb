{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### Abstract from a part of the book \"Practical Machine Learning and Image Processing\" (Himanshu Singh)\n### All the code is commented bacause SIFT algorithm wouldn't work. OpenCV does not support it anymore.\n### Content:\n* Feature mapping using the **S**cale-**I**nvariant **F**eature **T**ransform (**SIFT**) algorithm\n* Image registration using the **Ran**dom **Sa**mple **C**onsensus (**RANSAC**) algorithm"},{"metadata":{},"cell_type":"markdown","source":"# Feature Mapping using the SIFT Algorithm\n### SIFT is a patented algorithm so newer versions of OpenCV are no longer supporting it. So I commented all the code, it won't work anyway.\nFeatures of the image that the SIFT algorithm tries to factor out during processing: Scale (zoomed-in or zoomed-out image); Rotation; Illumination; Perspective.\n#### Step by step processes of using the SIFT Algorithm:\n1. Find and constructing a space to ensure scale invariance\n2. Find the difference between gaussians\n3. Find the important points present inside the image\n4. Remove the unimportant points to make efficient comparisons\n5. Provide orientation to the important points found in step 3\n6. Identifying the key features uniquely"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"scrolled":true},"cell_type":"code","source":"# import cv2\n# from pylab import *\n# from skimage import io\n# import numpy as np\n# import matplotlib.pyplot as plt\n\n# def extract_sift_features(img):\n#     sift_initialize = cv2.xfeatures2d.SIFT_create()\n#     key_points, descriptors = sift_initialize.detectAndCompute(img, None)\n#     return key_points, descriptors\n\n# def showing_sift_features(img1, img2, key_points):\n#     return plt.imshow(cv2.drawKeypoints(img1, key_points, img2.copy()))\n\n# # THE BELLOW CODE DOESN'T WORK IF THE IMAGES HAVE UNICODE CHARACTERES IN THEIR PATH\n# # OpenCV does not accept it\n# # So the files are directly inside the '../input' folder I don't know why:\n# img1 = cv2.imread('../input/tajone.jpg')\n# img2 = cv2.imread('../input/tajtwo.jpg')\n\n# # converting to gray:\n# img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n# img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n\n# #Key points:\n# img1_key_points, img1_descriptors = extract_sift_features(img1_gray)\n# img2_key_points, img2_descriptors = extract_sift_features(img2_gray)\n\n# print('Displaying SIFT features:')\n# showing_sift_features(img1_gray, img1, img1_key_points)\n\n# norm = cv2.NORM_L2\n# bruteForce = cv2.BFMatcher(norm)\n# matches = bruteForce.match(Image1_descriptors, Image2_descriptors)\n\n# matches = sorted(matches, key = lambda match:match.distance)\n# matched_img = cv2.drawMatches(\n# Image1, Image1_key_points,\n# Image2, Image2_key_points,\n# matches[:100], Image2.copy())\n# plt.figure(figsize=(100,300))\n# plt.imshow(matched_img)","execution_count":19,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image Registration using RANSAC algorithm\n### It uses the SIFT algorithm in the 'Align' part, so it won't work here. OpenCV do not cover it.\nImage Registration: process of putting one image over the other, at exactly the same place as the previous.\n#### RANSAC is one of the best algorithms for image registration. It consists of 4 steps:\n1. Feature detection and extraction\n2. Feature matching\n3. Transformation function fitting\n4. Image transformation and image resampling"},{"metadata":{},"cell_type":"markdown","source":"#### Here is the complete code, just for registering:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ############## Ransac.py: contains the entire RANSAC algorithm...\n# import numpy as np\n# from Affine import *\n\n# K=3\n# threshold=1\n\n# ITER_NUM = 2000\n\n# def residual_lengths(X, Y, s, t):\n#     e = np.dot(X, s) + Y\n#     diff_square = np.power(e - t, 2)\n#     residual = np.sqrt(np.sum(diff_square, axis=0))\n#     return residual\n# def ransac_fit(pts_s, pts_t):\n#     inliers_num = 0\n#     A = None\n#     t = None\n#     inliers = None\n#     for i in range(ITER_NUM):\n#         idx = np.random.randint(0, pts_s.shape[1], (K, 1))\n#         A_tmp, t_tmp = estimate_affine(pts_s[:, idx], pts_t[:, idx])\n#         residual = residual_lengths(A_tmp, t_tmp, pts_s, pts_t)\n#         if not(residual is None):\n#             inliers_tmp = np.where(residual < threshold)\n#             inliers_num_tmp = len(inliers_tmp[0])\n#             if inliers_num_tmp > inliers_num:\n#                 inliers_num = inliers_num_tmp\n#                 inliers = inliers_tmp\n#                 A = A_tmp\n#                 t = t_tmp\n#         else:\n#             pass\n#     return A, t, inliers\n\n# ############## Affine.py:\n# import numpy as np\n\n# def estimate_affine(s, t):\n#     num = s.shape[1]\n#     M = np.zeros((2 * num, 6))\n#     for i in range(num):\n#         temp = [[s[0, i], s[1, i], 0, 0, 1, 0], [0, 0, s[0, i], s[1, i], 0, 1]]\n#         M[2 * i: 2 * i + 2, :] = np.array(temp)\n#     b = t.T.reshape((2 * num, 1))\n#     theta = np.linalg.lstsq(M, b)[0]\n#     X = theta[:4].reshape((2, 2))\n#     Y = theta[4:]\n#     return X, Y\n\n# ############## Align.py:\n# import numpy as np\n# from Ransac import *\n# import cv2\n# from Affine import *\n\n# def extract_SIFT(img):\n#     img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n#     sift = cv2.xfeatures2d.SIFT_create()\n#     kp, desc = sift.detectAndCompute(img_gray, None)\n#     kp = np.array([p.pt for p in kp]).T\n#     return kp, desc\n# def match_SIFT(descriptor_source, descriptor_target):\n#     bf = cv2.BFMatcher()\n#     matches = bf.knnMatch(descriptor_source, descriptor_target, k=2)\n#     pos = np.array([], dtype=np.int32).reshape((0, 2))\n#     matches_num = len(matches)\n#     for i in range(matches_num):\n#         if matches[i][0].distance <= 0.8 * matches[i][1].distance:\n#             temp = np.array([matches[i][0].queryIdx, matches[i][0].trainIdx])\n#             pos = np.vstack((pos, temp))\n#     return pos\n# def affine_matrix(s, t, pos):\n#     s = s[:, pos[:, 0]]\n#     t = t[:, pos[:, 1]]\n#     _, _, inliers = ransac_fit(s, t)\n#     s = s[:, inliers[0]]\n#     t = t[:, inliers[0]]\n#     A, t = estimate_affine(s, t)\n#     M = np.hstack((A, t))\n#     return M\n\n# ############## Main Code:\n# import numpy as np\n# import cv2\n# from Ransac import *\n# from Affine import *\n# from Align import *\n\n# img_source = cv2.imread(\"2.jpg\")\n# img_target = cv2.imread(\"target.jpg\")\n\n# keypoint_source, descriptor_source = extract_SIFT(img_source)\n# keypoint_target, descriptor_target = extract_SIFT(img_target)\n\n# pos = match_SIFT(descriptor_source, descriptor_target)\n\n# H = affine_matrix(keypoint_source, keypoint_target, pos)\n# rows, cols, _ = img_target.shape\n# warp = cv2.warpAffine(img_source, H, (cols, rows))\n# merge = np.uint8(img_target * 0.5 + warp * 0.5)\n\n# cv2.imshow('img', merge)\n# cv2.waitKey(0)\n# cv2.destroyAllWindows()","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('tears in heaven')","execution_count":21,"outputs":[{"output_type":"stream","text":"tears in heaven\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\ncv2.BFMatcher().knnMatch()","execution_count":22,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"DescriptorMatcher.knnMatch() missing required argument 'queryDescriptors' (pos 1)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-15a937a30020>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBFMatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknnMatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: DescriptorMatcher.knnMatch() missing required argument 'queryDescriptors' (pos 1)"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}