{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Classification Chapter","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# MNIST dataset","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from sklearn.datasets import fetch_openml\nmnist = fetch_openml('mnist_784', version=1)\nmnist.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = mnist['data'], mnist['target']\nX.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nsome_digit = X[0]\nsome_digit_image = some_digit.reshape(28, 28)\n\nplt.imshow(some_digit_image, cmap='binary')\nplt.axis('off')\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\ny[0] ## is a string must turn this into number\ny = y.astype(np.uint8)\ny[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## creating the train and the test set as always, the MNIST dataset is \n## already split into a training set(the first 60,000 images) and a test\n## set (the last 10,000) images.\n\nX_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training a Binary Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## first of all i'll try to identify if the number is a 5\ny_train_5 = (y_train == 5) ## labels of the train set, 60,000 in size\ny_test_5 = (y_test == 5) ## labels of test set, 10,000 in size\ny_train_5, y_test_5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\n\nsgd_clf = SGDClassifier(random_state=42)\nsgd_clf.fit(X_train, y_train_5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd_clf.predict([X_train[0]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"measuring performance of classifiers is trickier than that of regressors","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Performance Measures\n# Many pages are dedicated to Performance Measures...","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Measuring acuracy using cross-validation:\nThe folowing code does roughly the same thing as the Scikit-Learn's `cross_val_score()` function, and it prints the same result","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold # performs stratified sampling to produce\nfrom sklearn.base import clone                      # folds that contain a representative ratio\n                                                    # of each class\nskfolds = StratifiedKFold(n_splits=3, random_state=42)\n\nfor train_index, test_index in skfolds.split(X_train, y_train_5): # Generate indices to split \n    clone_clf = clone(sgd_clf) ## using clone()                   # data into training and test set.\n    X_train_folds = X_train[train_index]\n    y_train_folds = y_train_5[train_index]\n    X_test_fold = X_train[test_index]\n    y_test_fold = y_train_5[test_index]\n    \n    print('train_index:', train_index)\n    print('test_index:', test_index)\n    \n    clone_clf.fit(X_train_folds, y_train_folds)\n    y_pred = clone_clf.predict(X_test_fold)\n    n_correct = sum(y_pred == y_test_fold)\n    print('score: ', n_correct / len(y_pred), '\\n-----------') ## outputs the ratio of correct predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#help(skfolds.split)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now using the proper `cross_val_score()` function to evaluate `SGDClassifier`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\ncross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, demonstrating why 'accuracy' is not a got performance measure:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator\n\nclass Never5Classifier(BaseEstimator):\n    def fit(self, X, y=None):\n        return self\n    def predict(self, X):\n        return np.zeros((len(X), 1), dtype=bool)\n\nnever_5_clf = Never5Classifier()\ncross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring='accuracy')\n## it will output about 90% accuracy, as there are around 90% non fives in the data set","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Confusion Matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_predict\ny_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n#with this, i can get a prediction for each instance in the training set\ny_train_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_train_5, y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A perfect classifier would have only true positives and true negatives:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_5_perfect_predictions = y_train_5\nconfusion_matrix(y_train_5, y_train_5_perfect_predictions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Precision and Recall:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score\nprecision = precision_score(y_train_5, y_train_pred) ## when it claims it is a 5, the sgd_clf is correct in (precision*100)% of the time\nrecall = recall_score(y_train_5, y_train_pred) ## (1 - recall) says % how many true 5s were not spot by the classifier\nprecision, recall                              ## that is it only detects (recall*100)% of the 5s    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tying Precision and Recall together, we have the `f1_score`, which is the harmonic mean of both:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nf1_score(y_train_5, y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## instead of calling the classifier's predict() method, you can call its decision_function() method,\n## which returns a score for each instance, and then use any threshold you want to make predictions\n## based on those scores:\ny_scores = sgd_clf.decision_function([some_digit])\ny_scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The `SGDClassifier` uses a threshold equal to 0:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 0  #threshold from the tradeoff between Precision and Recall\ny_some_digit_pred = (y_scores > threshold)\ny_some_digit_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Raising the threshold:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 8000  #threshold from the tradeoff between Precision and Recall\ny_some_digit_pred = (y_scores > threshold)\ny_some_digit_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This confirms that raising the threshold reduces recall. That is what were previously a True positive is now a false negative. Lowering the threshold would reduce the precision.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,\n                             method='decision_function')\n#wtih 'decision_function' as the method, i'll get the scores of all instances in the training set\ny_scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now i'll use `precision_recall_curve()` function to compute precision and recall for all possible thresholds:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\nprecisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n\ndef plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], 'b--', label='Precision')\n    plt.plot(thresholds, recalls[:-1], 'g-', label='Recall')\n    plt.xlabel('Threshold')\n    plt.legend(loc='upper left')\n    plt.ylim([0,1])\n\n\nplot_precision_recall_vs_threshold(precisions, recalls, thresholds)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Precision may sometimes go down when you raise the threshold.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(recalls, precisions)\nplt.xlabel('Recalls')\nplt.ylabel('Precisions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, to show that i can create a classifier that can give me virtually any precision i want, i'll find the lowest threshold that gives me at least 90% **precision**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]\n# to make predictions (on the training set for now), instead of calling the classifier's predict() method,\n# i'll run this code:\ny_train_pred_90 = (y_scores >= threshold_90_precision)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now checking these predictions' `precision` and `recall`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"prec_s = precision_score(y_train_5, y_train_pred_90)\nrec_s = recall_score(y_train_5, y_train_pred_90)\nprec_s, rec_s","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"90% of precision, exactly what i forced it to be, but the recall is too low. A high precision classifier is not very usefull if its recall is too low.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# The ROC curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_train_5, y_scores)\nfpr, tpr = false_positive_rate, true_positive_rate\n\ndef plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--') #Dashed diagonal line\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate (Recall)')\n\nplot_roc_curve(fpr, tpr)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A good classifier will be far from the dotted line, towards the top left corner. A good way to measure the performance is to value the area under the curve (AUC). A perfect classifier will have AUC = 1, and a random one would have AUC = 0.5. We can test it with `roc_auc_score`:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nroc_auc_score(y_train_5, y_scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now I'll trian a `RandomForestClassifier` and compare its ROC curve and ROC AUC to those of the `SGDClassifier`","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The `RandomForestClassifier` class does not have a `decision_function()` method. Insteat it has a `predict_proba()` method.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## The predict_proba() method returns an array containing a row per instance\n## and a column per class, each containing the probability that the given \n## instance belongs to the given class\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nforest_clf = RandomForestClassifier(random_state=42)\ny_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3,\n                                    method='predict_proba')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `roc_curve()` function expects labels and scores, but instead of scores I can give it class probabilities:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_scores_forest = y_probas_forest[:, 1] # score = proba of positive class\nfpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5, y_scores_forest)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now ploting the ROC curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(fpr, tpr, 'b:', label='SGD')\nplot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\nplt.legend(loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(y_train_5, y_scores_forest)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Random Forest classifier is superior to the SGD classifier because its ROC curve is much closer to the top-left corner, and it has a greater AUC.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**LATER I SHOULD TRY SEEING THAT THE FOREST HAS A 99% PRECISION AND 86.6% RECAL !!!**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Message from the author of the book: \"You now know how to train binary classifiers, choose the appropriate metric for your task, evaluate your classifiers using cross-validation, select the precision/recall tradeoff that fits your needs, and use ROC curves and ROC AUC scores to compare various models.\"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Multiclass Classification","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Trying a Support Vector Machine classifier:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm_clf = SVC()\nsvm_clf.fit(X_train, y_train)\n## under the hood scikit-learn is using the OvO strategy: it trained 45 binary classifiers,\n## when we call .predicti() it gets their decision scores for the image, and selected the class \n## that won the most duels. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_clf.predict([some_digit])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"some_digit_scores = svm_clf.decision_function([some_digit])\nsome_digit_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_clf.classes_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I can use`OneVsOneClassifier` or `OneVsRestClassifier` classes if I wanna choose which method to use. This code creates a multiclass classifier using the OvR strategy, based on SVC:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.multiclass import OneVsRestClassifier\novr_clf = OneVsRestClassifier(SVC())\novr_clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training a `SGDClassifier` (or a `RandomForestClassifier`) is just as easy:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd_clf.fit(X_train, y_train)\nsgd_clf.predict([some_digit])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the cell above Scikit-Learn did not have to run OvR or OvO because SGD classifiers can directly classify instances into multiple classes (as `RandomForestClassifier` can)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd_clf.decision_function([some_digit])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluating:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring='accuracy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scaling inputs increases accuracy...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\ncross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring='accuracy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Error Analysis\nAnalysing the type of errors my model does","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\nconf_mx = confusion_matrix(y_train, y_train_pred)\nconf_mx","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image representation of the confusion matrix:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.matshow(conf_mx, cmap=plt.cm.gray)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}